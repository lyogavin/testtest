{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import time\n",
    "\n",
    "\n",
    "def get_dated_filename(filename):\n",
    "    return '{}.{}_{}'.format(filename, time.strftime(\"%d-%m-%Y\"), time.strftime(\"%X\"))\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "'''\n",
    "Another CTR comp and so i suspect libffm will play its part, after all it is an atomic bomb for this kind of stuff.\n",
    "A sci-kit learn inspired script to convert pandas dataframes into libFFM style data.\n",
    "\n",
    "The script is fairly hacky (hey thats Kaggle) and takes a little while to run a huge dataset.\n",
    "The key to using this class is setting up the features dtypes correctly for output (ammend transform to suit your needs)\n",
    "\n",
    "Example below\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "import sys\n",
    "import gc\n",
    "\n",
    "use_sample = False\n",
    "\n",
    "gen_test_input = True\n",
    "\n",
    "path = '../input/' \n",
    "path_train = path + 'train.csv'\n",
    "path_train_sample = path + 'train_sample.csv'\n",
    "path_test = path + 'test.csv'\n",
    "path_test_sample = path + 'test_sample.csv'\n",
    "\n",
    "train_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time', 'is_attributed']\n",
    "test_cols = ['ip', 'app', 'device', 'os', 'channel', 'click_time']\n",
    "\n",
    "categorical = ['app', 'device', 'os', 'channel', 'hour']\n",
    "\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }\n",
    "        \n",
    "skip = range(1, 140000000)\n",
    "print(\"Loading Data\")\n",
    "#skiprows=skip,\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "def prepare_data(data, training_day, profile_days, sample_count=1, with_hist_profile=True):\n",
    "    if sample_count != 1:\n",
    "        #sample 1/4 of the data:\n",
    "        data = data.set_index('ip').loc[lambda x: (x.index + 401) % sample_count == 0].reset_index()\n",
    "        len_train = len(data)\n",
    "        print('len after sample:', len_train)\n",
    "\n",
    "    train_ip_contains_training_day = None\n",
    "    train_ip_contains_training_day_attributed = None\n",
    "\n",
    "    if with_hist_profile:\n",
    "        train_ip_contains_training_day = data.groupby('ip').filter(lambda x: x['day'].max() == training_day)\n",
    "\n",
    "        print('train_ip_contains_training_day', train_ip_contains_training_day)\n",
    "        print('train_ip_contains_training_day unique ips:', len(train_ip_contains_training_day['ip'].unique()))\n",
    "\n",
    "        train_ip_contains_training_day = train_ip_contains_training_day  \\\n",
    "            .query('day < {0} & day > {1}'.format(training_day, training_day - 1 - profile_days) )\n",
    "        print('train_ip_contains_training_day unique ips:', len(train_ip_contains_training_day['ip'].unique()))\n",
    "\n",
    "        print('split attributed data:')\n",
    "        train_ip_contains_training_day_attributed = train_ip_contains_training_day.query('is_attributed == 1')\n",
    "        print('len:',len(train_ip_contains_training_day_attributed))\n",
    "\n",
    "    #only use data on 9 to train, but data before 9 as features\n",
    "    train = data.query('day == {}'.format(training_day))\n",
    "    print('training data len:', len(train))\n",
    "    \n",
    "    return train, \\\n",
    "           train_ip_contains_training_day, train_ip_contains_training_day_attributed\n",
    "\n",
    "\n",
    "def add_statistic_feature(group_by_cols, training, training_hist, training_hist_attribution,\n",
    "                          with_hist, counting_col='channel', cast_type=False, qcut_count=0, discretization=0):\n",
    "    features_added = []\n",
    "    feature_name_added = '_'.join(group_by_cols) + 'count'\n",
    "    print('count ip with group by:', group_by_cols)\n",
    "    n_chans = training[group_by_cols + [counting_col]].groupby(by=group_by_cols)[[counting_col]] \\\n",
    "        .count().reset_index().rename(columns={counting_col: feature_name_added})\n",
    "    training = training.merge(n_chans, on=group_by_cols, how='left')\n",
    "    del n_chans\n",
    "    gc.collect()\n",
    "    training[feature_name_added] = training[feature_name_added].astype('uint16')\n",
    "    if qcut_count != 0:\n",
    "        print('before qcut', feature_name_added, training[feature_name_added].describe())\n",
    "        quantile_cut = training[feature_name_added].quantile(qcut_count)\n",
    "        training[feature_name_added] = training[feature_name_added].apply(\n",
    "            lambda x: x if x < quantile_cut else 65535).astype('uint16')\n",
    "        print('after qcut', feature_name_added, training[feature_name_added].describe())\n",
    "    if discretization != 0:\n",
    "        print('before qcut', feature_name_added, training[feature_name_added].describe())\n",
    "        training[feature_name_added] = pd.qcut(training[feature_name_added], discretization, labels=False,\n",
    "                                               duplicates='drop').fillna(0).astype('uint16')\n",
    "        print('after qcut', feature_name_added, training[feature_name_added].describe())\n",
    "\n",
    "    features_added.append(feature_name_added)\n",
    "\n",
    "    if with_hist:\n",
    "        print('count ip with group by in hist data:', group_by_cols)\n",
    "        feature_name_added = '_'.join(group_by_cols) + \"count_in_hist\"\n",
    "        n_chans = training_hist[group_by_cols + [counting_col]].groupby(by=group_by_cols)[[counting_col]] \\\n",
    "            .count().reset_index().rename(columns={counting_col: feature_name_added})\n",
    "        training = training.merge(n_chans, on=group_by_cols, how='left')\n",
    "        del n_chans\n",
    "        gc.collect()\n",
    "        print('count ip attribution with group by in hist data:', group_by_cols)\n",
    "        feature_name_added1 = '_'.join(group_by_cols) + \"count_attribution_in_hist\"\n",
    "        n_chans = training_hist_attribution[group_by_cols + [counting_col]] \\\n",
    "            .groupby(by=group_by_cols)[[counting_col]] \\\n",
    "            .count().reset_index().rename(columns={counting_col: feature_name_added1})\n",
    "        training = training.merge(n_chans, on=group_by_cols, how='left')\n",
    "        del n_chans\n",
    "        gc.collect()\n",
    "\n",
    "        feature_name_added2 = '_'.join(group_by_cols) + \"count_attribution_rate_in_hist\"\n",
    "        training[feature_name_added2] = \\\n",
    "            training[feature_name_added1] / training[feature_name_added] * 1000.0\n",
    "\n",
    "        if qcut_count != 0:\n",
    "            print('before qcut', feature_name_added, training[feature_name_added].describe())\n",
    "            quantile_cut = training[feature_name_added].quantile(qcut_count)\n",
    "            training[feature_name_added] = training[feature_name_added].apply(lambda x: x if x < quantile_cut else -1)\n",
    "            print('after qcut', feature_name_added, training[feature_name_added].describe())\n",
    "\n",
    "        if cast_type:\n",
    "            training[feature_name_added] = training[feature_name_added].fillna(0).astype('uint16')\n",
    "        if discretization != 0:\n",
    "            print('before qcut', feature_name_added, training[feature_name_added].describe())\n",
    "            training[feature_name_added] = pd.qcut(training[feature_name_added], discretization, labels=False,\n",
    "                                                   duplicates='drop').fillna(0).astype('uint16')\n",
    "            print('after qcut', feature_name_added, training[feature_name_added].describe())\n",
    "\n",
    "\n",
    "\n",
    "        if qcut_count != 0:\n",
    "            print('before qcut', feature_name_added1, training[feature_name_added1].describe())\n",
    "            quantile_cut = training[feature_name_added1].quantile(qcut_count)\n",
    "            training[feature_name_added1] = training[feature_name_added1].apply(lambda x: x if x < quantile_cut else -1)\n",
    "            print('after qcut', feature_name_added1, training[feature_name_added1].describe())\n",
    "\n",
    "        if cast_type:\n",
    "            training[feature_name_added1] = training[feature_name_added1].fillna(0).astype('uint16')\n",
    "            #training = training.astype({feature_name_added1:'uint16'})\n",
    "            print(training[feature_name_added1])\n",
    "        if discretization != 0:\n",
    "            print('before qcut', feature_name_added1, training[feature_name_added1].describe())\n",
    "            training[feature_name_added1] = pd.qcut(training[feature_name_added1], discretization, labels=False,\n",
    "                                                    duplicates='drop').fillna(0).astype('uint16')\n",
    "            print('after qcut', feature_name_added1, training[feature_name_added1].describe())\n",
    "        # training[feature_name_added1] = training[feature_name_added1].astype('uint16')\n",
    "\n",
    "\n",
    "        if cast_type:\n",
    "            training[feature_name_added2] = training[feature_name_added2].fillna(0).astype('uint16')\n",
    "\n",
    "        features_added.append(feature_name_added)\n",
    "        features_added.append(feature_name_added1)\n",
    "        features_added.append(feature_name_added2)\n",
    "\n",
    "    print('added features:', features_added)\n",
    "\n",
    "    return training, features_added\n",
    "\n",
    "def generate_counting_history_features(data, history, history_attribution, with_hist_profile = True):\n",
    "        \n",
    "    new_features = []\n",
    "\n",
    "    # Count by IP,DAY,HOUR\n",
    "    print('a given IP address within each hour...')\n",
    "    data, features_added = add_statistic_feature(['ip','day','hour'], data, history, history_attribution, False)\n",
    "    new_features = new_features + features_added\n",
    "    gc.collect()\n",
    "\n",
    "    # Count by IP and APP\n",
    "    data, features_added = add_statistic_feature(['ip','app'], data, history, history_attribution, with_hist_profile)\n",
    "    new_features = new_features + features_added\n",
    "    \n",
    "    # Count by IP and channel\n",
    "    data, features_added = add_statistic_feature(['ip','channel'], data, history, history_attribution, with_hist_profile, counting_col='os')\n",
    "    new_features = new_features + features_added\n",
    "    \n",
    "    # Count by IP and channel app\n",
    "    data, features_added = add_statistic_feature(['ip','channel', 'app'], data, history, history_attribution, with_hist_profile, counting_col='os')\n",
    "    new_features = new_features + features_added\n",
    "    \n",
    "    data, features_added  = add_statistic_feature(['ip','app','os'], data, history, history_attribution, with_hist_profile)\n",
    "    new_features = new_features + features_added\n",
    "\n",
    "    #######\n",
    "    # Count by IP\n",
    "    data, features_added  = add_statistic_feature(['ip'], data, history, history_attribution, with_hist_profile)\n",
    "    new_features = new_features + features_added\n",
    "\n",
    "    # Count by IP HOUR CHANNEL                                               \n",
    "    data, features_added  = add_statistic_feature(['ip','hour','channel'],\n",
    "                                                  data, history, history_attribution, with_hist_profile, counting_col='os')\n",
    "    new_features = new_features + features_added\n",
    "\n",
    "    # Count by IP HOUR Device\n",
    "    data, features_added  = add_statistic_feature(['ip','hour','os'],\n",
    "                                                  data, history, history_attribution, with_hist_profile)\n",
    "    new_features = new_features + features_added\n",
    "\n",
    "    data, features_added  = add_statistic_feature(['ip','hour','app'],\n",
    "                                                  data, history, history_attribution, with_hist_profile)\n",
    "    new_features = new_features + features_added\n",
    "\n",
    "    data, features_added  = add_statistic_feature(['ip','hour','device'],\n",
    "                                                  data, history, history_attribution, with_hist_profile)\n",
    "    new_features = new_features + features_added\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    remove_hist_profile_count=4\n",
    "    if remove_hist_profile_count != 0:\n",
    "        data = data.query('ipcount_in_hist > {}'.format(remove_hist_profile_count))\n",
    "    \n",
    "    return data, new_features\n",
    "\n",
    "#test['hour'] = test[\"click_time\"].dt.hour.astype('uint8')\n",
    "#test['day'] = test[\"click_time\"].dt.day.astype('uint8')\n",
    "\n",
    "\n",
    "\n",
    "def gen_train_df(with_hist_profile = True):\n",
    "    train = pd.read_csv(path_train_sample if use_sample else path_train, dtype=dtypes,\n",
    "            header=0,usecols=train_cols,parse_dates=[\"click_time\"])#.sample(1000)\n",
    "\n",
    "\n",
    "    len_train = len(train)\n",
    "    print('The initial size of the train set is', len_train)\n",
    "    print('Binding the training and test set together...')\n",
    "\n",
    "\n",
    "    print(\"Creating new time features in train: 'hour' and 'day'...\")\n",
    "    train['hour'] = train[\"click_time\"].dt.hour.astype('uint8')\n",
    "    train['day'] = train[\"click_time\"].dt.day.astype('uint8')\n",
    "\n",
    "    train, train_ip_contains_training_day, train_ip_contains_training_day_attributed =  \\\n",
    "        prepare_data(train, 9, 3, 4, with_hist_profile)\n",
    "\n",
    "    train, new_features = generate_counting_history_features(train, train_ip_contains_training_day,\n",
    "                                                             train_ip_contains_training_day_attributed,\n",
    "                                                             with_hist_profile)\n",
    "\n",
    "    print('train data:', train)\n",
    "    print('new features:', new_features)\n",
    "\n",
    "    val = train.set_index('ip').loc[lambda x: (x.index) % 17 == 0].reset_index()\n",
    "    print(val)\n",
    "    print('The size of the validation set is ', len(val))\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    train = train.set_index('ip').loc[lambda x: (x.index) % 17 != 0].reset_index()\n",
    "    print('The size of the train set is ', len(train))\n",
    "\n",
    "    target = 'is_attributed'\n",
    "    train[target] = train[target].astype('uint8')\n",
    "    train.info()\n",
    "\n",
    "    if use_sample:\n",
    "        train.to_csv(get_dated_filename('training_sample.csv'), index=False)\n",
    "        val.to_csv(get_dated_filename('val_sample.csv'), index=False)\n",
    "    else:\n",
    "        train.to_csv(get_dated_filename('training.csv'), index=False)\n",
    "        val.to_csv(get_dated_filename('val.csv'), index=False)\n",
    "\n",
    "    print('save dtypes')\n",
    "\n",
    "    y = {k: str(v) for k, v in train.dtypes.to_dict().items()}\n",
    "    print(y)\n",
    "    del y['click_time']\n",
    "    #del y['Unnamed: 0']\n",
    "    pickle.dump(y,open('output_dtypes.pickle','wb'))\n",
    "\n",
    "    #sys.exit(0)\n",
    "    return train, val, new_features\n",
    "\n",
    "\n",
    "train_lgbm = False\n",
    "\n",
    "def train_lgbm(train, val, new_features):\n",
    "#if train_lgbm:\n",
    "\n",
    "    # In[7]:\n",
    "    target = 'is_attributed'\n",
    "\n",
    "    predictors0 = ['device', 'app', 'os', 'channel', 'hour', # Starter Vars, Then new features below\n",
    "                  'ip_day_hourcount','ipcount','ip_appcount', 'ip_app_oscount',\n",
    "                  \"ip_hour_channelcount\", \"ip_hour_oscount\", \"ip_hour_appcount\",\"ip_hour_devicecount\"]\n",
    "\n",
    "    predictors1 = categorical + new_features\n",
    "    #for ii in new_features:\n",
    "    #    predictors1 = predictors1 + ii\n",
    "    #print(predictors1)\n",
    "    gc.collect()\n",
    "\n",
    "    #train.fillna(value={x:-1 for x in new_features})\n",
    "\n",
    "    print(\"Preparing the datasets for training...\")\n",
    "\n",
    "    params = {\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.1,\n",
    "        'num_leaves': 7,\n",
    "        'max_depth': 4,\n",
    "        'min_child_samples': 100,\n",
    "        'max_bin': 150,\n",
    "        'subsample': 0.7,\n",
    "        'subsample_freq': 1,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'min_child_weight': 0,\n",
    "        'subsample_for_bin': 200000,\n",
    "        'min_split_gain': 0,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,\n",
    "        'nthread': 5,\n",
    "        'verbose': 9,\n",
    "        #'is_unbalance': True,\n",
    "        'scale_pos_weight':99\n",
    "        }\n",
    "\n",
    "    predictors_to_train = [predictors1]\n",
    "\n",
    "    for predictors in predictors_to_train:\n",
    "        print('training with :', predictors)\n",
    "        #print('training data: ', train[predictors].values)\n",
    "        #print('validation data: ', val[predictors].values)\n",
    "        dtrain = lgb.Dataset(train[predictors].values, label=train[target].values,\n",
    "                              feature_name=predictors,\n",
    "                              categorical_feature=categorical\n",
    "                              )\n",
    "        dvalid = lgb.Dataset(val[predictors].values, label=val[target].values,\n",
    "                              feature_name=predictors,\n",
    "                              categorical_feature=categorical\n",
    "                              )\n",
    "\n",
    "        evals_results = {}\n",
    "        print(\"Training the model...\")\n",
    "\n",
    "        lgb_model = lgb.train(params,\n",
    "                         dtrain,\n",
    "                         valid_sets=[dtrain, dvalid],\n",
    "                         valid_names=['train','valid'],\n",
    "                         evals_result=evals_results,\n",
    "                         num_boost_round=1000,\n",
    "                         early_stopping_rounds=30,\n",
    "                         verbose_eval=50,\n",
    "                         feval=None)\n",
    "\n",
    "        #del train\n",
    "        #del val\n",
    "        #gc.collect()\n",
    "\n",
    "        # Nick's Feature Importance Plot\n",
    "        import matplotlib.pyplot as plt\n",
    "        f, ax = plt.subplots(figsize=[7,10])\n",
    "        lgb.plot_importance(lgb_model, ax=ax, max_num_features=len(predictors))\n",
    "        plt.title(\"Light GBM Feature Importance\")\n",
    "        plt.savefig('feature_import.png')\n",
    "\n",
    "        # Feature names:\n",
    "        print('Feature names:', lgb_model.feature_name())\n",
    "        # Feature importances:\n",
    "        print('Feature importances:', list(lgb_model.feature_importance()))\n",
    "\n",
    "        feature_imp = pd.DataFrame(lgb_model.feature_name(),list(lgb_model.feature_importance()))\n",
    "\n",
    "        lgb_model.save_model(get_dated_filename('model.txt'))\n",
    "\n",
    "        print('gen val prediction')\n",
    "        val_prediction = lgb_model.predict(val[predictors1], num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "        print(\"Writing the val_prediction into a csv file...\")\n",
    "\n",
    "        pd.Series(val_prediction).to_csv(get_dated_filename(\"val_prediction.csv\"), index=False)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "for_test = True\n",
    "\n",
    "def gen_test_df(with_hist_profile = True):\n",
    "    #del train\n",
    "    #del test\n",
    "    #gc.collect()\n",
    "\n",
    "    #prepare test data:\n",
    "    if with_hist_profile:\n",
    "        train = pd.read_csv(path_train, dtype=dtypes,\n",
    "                header=0,usecols=train_cols,parse_dates=[\"click_time\"])#.sample(1000)\n",
    "    test = pd.read_csv(path_test if not use_sample else path_test_sample, dtype=dtypes, header=0,\n",
    "            usecols=test_cols,parse_dates=[\"click_time\"])#.sample(1000)\n",
    "    if with_hist_profile:\n",
    "        train=train.append(test)\n",
    "    else:\n",
    "        train = test\n",
    "    del test\n",
    "    gc.collect()\n",
    "    print(\"Creating new time features in train: 'hour' and 'day'...\")\n",
    "    train['hour'] = train[\"click_time\"].dt.hour.astype('uint8')\n",
    "    train['day'] = train[\"click_time\"].dt.day.astype('uint8')\n",
    "    \n",
    "    train, train_ip_contains_training_day, train_ip_contains_training_day_attributed = \\\n",
    "        prepare_data(train, 10, 3, 1, with_hist_profile)\n",
    "\n",
    "    train, new_features = generate_counting_history_features(train, train_ip_contains_training_day, \n",
    "                                                             train_ip_contains_training_day_attributed,\n",
    "                                                             with_hist_profile)\n",
    "\n",
    "    train['is_attributed'] = 0\n",
    "    train.to_csv(get_dated_filename('test_to_predict.csv' + '.sample' if use_sample else ''), index=False)\n",
    "\n",
    "    return train, new_features\n",
    "\n",
    "# In[ ]:\n",
    "to_submit = False\n",
    "\n",
    "if to_submit:\n",
    "    print('test data:', train)\n",
    "\n",
    "    print('new features:', new_features)\n",
    "    print(\"Preparing data for submission...\")\n",
    "\n",
    "    submit = pd.read_csv(path_test, dtype='int', usecols=['click_id'])\n",
    "    print('submit test len:', len(submit))\n",
    "    print(\"Predicting the submission data...\")\n",
    "    submit['is_attributed'] = lgb_model.predict(train[predictors1], num_iteration=lgb_model.best_iteration)\n",
    "\n",
    "    print(\"Writing the submission data into a csv file...\")\n",
    "\n",
    "    submit.to_csv(get_dated_filename(\"submission_notebook.csv\"),index=False)\n",
    "\n",
    "    print(\"All done...\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gen_ffm_data():\n",
    "    train, val, new_features = gen_train_df(False)\n",
    "    train_len = len(train)\n",
    "    val_len = len(val)\n",
    "    gc.collect()\n",
    "    test, _ = gen_test_df(False)\n",
    "    test_len= len(test)\n",
    "    gc.collect()\n",
    "\n",
    "    print('train({}) val({}) test({}) generated'.format(train_len, val_len,test_len))\n",
    "\n",
    "\n",
    "    train = train.append(val)\n",
    "    test = train.append(test)\n",
    "\n",
    "    del train\n",
    "    del val\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    print(test)\n",
    "\n",
    "\n",
    "\n",
    "train, val, new_features = gen_train_df(True)\n",
    "\n",
    "train_lgbm(train, val, new_features)\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new time features in train: 'hour' and 'day'...\n",
      "train_ip_contains_training_day           app  channel          click_time  device      ip  is_attributed  os  \\\n",
      "0           3      379 2017-11-06 14:32:21       1   83230            0.0  13   \n",
      "1           3      379 2017-11-06 14:33:34       1   17357            0.0  19   \n",
      "2           3      379 2017-11-06 14:34:12       1   35810            0.0  13   \n",
      "3          14      478 2017-11-06 14:34:52       1   45745            0.0  13   \n",
      "5           3      379 2017-11-06 14:36:26       1   18787            0.0  16   \n",
      "6           3      379 2017-11-06 14:37:44       1  103022            0.0  23   \n",
      "7           3      379 2017-11-06 14:37:59       1  114221            0.0  19   \n",
      "9          64      459 2017-11-06 14:38:23       1   74544            0.0  22   \n",
      "11          3      379 2017-11-06 14:38:51       1  105861            0.0  13   \n",
      "13          3      379 2017-11-06 14:40:16       1  124979            0.0  18   \n",
      "14          3      379 2017-11-06 14:40:39       1   38816            0.0  18   \n",
      "15          3      379 2017-11-06 14:40:51       1   80447            0.0  19   \n",
      "17          3      379 2017-11-06 14:43:14       1   57576            0.0  19   \n",
      "18          3      379 2017-11-06 14:43:25       1    7755            0.0  13   \n",
      "19          3      379 2017-11-06 14:43:51       1   91749            0.0  19   \n",
      "20          3      379 2017-11-06 14:44:02       1   50694            0.0  18   \n",
      "21          3      379 2017-11-06 14:44:15       1  111385            0.0  18   \n",
      "22         14      478 2017-11-06 14:44:51       1  125222            0.0   3   \n",
      "24          3      379 2017-11-06 14:44:52       1   53418            0.0  17   \n",
      "26          3      379 2017-11-06 14:48:07       1   47902            0.0  17   \n",
      "30          3      379 2017-11-06 14:49:43       1   73503            0.0  18   \n",
      "31          3      379 2017-11-06 14:50:29       1   28739            0.0  13   \n",
      "33          3      379 2017-11-06 14:52:13       1   30986            0.0  19   \n",
      "34          3      379 2017-11-06 14:52:58       1    2805            0.0  16   \n",
      "35         18      376 2017-11-06 14:53:23       1  103175            0.0  17   \n",
      "36          3      379 2017-11-06 14:53:39       1   23550            0.0  13   \n",
      "37         64      459 2017-11-06 14:54:59       1   29045            0.0  13   \n",
      "38          3      379 2017-11-06 14:55:25       1   74715            0.0  19   \n",
      "40          3      379 2017-11-06 14:56:11       1   31529            0.0  15   \n",
      "41          3      379 2017-11-06 14:56:12       1   16760            0.0  15   \n",
      "...       ...      ...                 ...     ...     ...            ...  ..   \n",
      "18790439   27      153 2017-11-10 15:00:00       1   51432            NaN  13   \n",
      "18790440   14      401 2017-11-10 15:00:00       1   14334            NaN  19   \n",
      "18790441    9      334 2017-11-10 15:00:00       1   16749            NaN  13   \n",
      "18790442   23      153 2017-11-10 15:00:00       1   17814            NaN  13   \n",
      "18790443   21      232 2017-11-10 15:00:00       1    8825            NaN  13   \n",
      "18790444    8      259 2017-11-10 15:00:00       2  115536            NaN  13   \n",
      "18790445    2      205 2017-11-10 15:00:00       1  121472            NaN  19   \n",
      "18790446   12      242 2017-11-10 15:00:00       1   38000            NaN  12   \n",
      "18790447    1      125 2017-11-10 15:00:00       1   66176            NaN  19   \n",
      "18790448    2      205 2017-11-10 15:00:00       1   25553            NaN  22   \n",
      "18790449   21      128 2017-11-10 15:00:00       2  119531            NaN  19   \n",
      "18790450   13      469 2017-11-10 15:00:00       1   14062            NaN  53   \n",
      "18790451   14      442 2017-11-10 15:00:00       1   48536            NaN  19   \n",
      "18790452    1      125 2017-11-10 15:00:00       1   93291            NaN  19   \n",
      "18790453    9      258 2017-11-10 15:00:00       1   93291            NaN  19   \n",
      "18790454    1      125 2017-11-10 15:00:00       1   55874            NaN  22   \n",
      "18790455    9      145 2017-11-10 15:00:00       1   93291            NaN  19   \n",
      "18790456    8      259 2017-11-10 15:00:00       1  100697            NaN  18   \n",
      "18790457   20      259 2017-11-10 15:00:00       1   93291            NaN  19   \n",
      "18790458    2      452 2017-11-10 15:00:00       1   85329            NaN  14   \n",
      "18790459   15      140 2017-11-10 15:00:00       1  102467            NaN  17   \n",
      "18790460    9      445 2017-11-10 15:00:00       1   80537            NaN  19   \n",
      "18790461    2      237 2017-11-10 15:00:00       2  101214            NaN  16   \n",
      "18790462   17      128 2017-11-10 15:00:00       1  113418            NaN  17   \n",
      "18790463   12      135 2017-11-10 15:00:00       1   69245            NaN  13   \n",
      "18790464    9      127 2017-11-10 15:00:00       1   99442            NaN  13   \n",
      "18790465   23      153 2017-11-10 15:00:00       1   88046            NaN  37   \n",
      "18790466   18      265 2017-11-10 15:00:00       1   81398            NaN  17   \n",
      "18790467   27      122 2017-11-10 15:00:00       1  123236            NaN  13   \n",
      "18790468   12      265 2017-11-10 15:00:00       2   73516            NaN  27   \n",
      "\n",
      "          hour  day  \n",
      "0           14    6  \n",
      "1           14    6  \n",
      "2           14    6  \n",
      "3           14    6  \n",
      "5           14    6  \n",
      "6           14    6  \n",
      "7           14    6  \n",
      "9           14    6  \n",
      "11          14    6  \n",
      "13          14    6  \n",
      "14          14    6  \n",
      "15          14    6  \n",
      "17          14    6  \n",
      "18          14    6  \n",
      "19          14    6  \n",
      "20          14    6  \n",
      "21          14    6  \n",
      "22          14    6  \n",
      "24          14    6  \n",
      "26          14    6  \n",
      "30          14    6  \n",
      "31          14    6  \n",
      "33          14    6  \n",
      "34          14    6  \n",
      "35          14    6  \n",
      "36          14    6  \n",
      "37          14    6  \n",
      "38          14    6  \n",
      "40          14    6  \n",
      "41          14    6  \n",
      "...        ...  ...  \n",
      "18790439    15   10  \n",
      "18790440    15   10  \n",
      "18790441    15   10  \n",
      "18790442    15   10  \n",
      "18790443    15   10  \n",
      "18790444    15   10  \n",
      "18790445    15   10  \n",
      "18790446    15   10  \n",
      "18790447    15   10  \n",
      "18790448    15   10  \n",
      "18790449    15   10  \n",
      "18790450    15   10  \n",
      "18790451    15   10  \n",
      "18790452    15   10  \n",
      "18790453    15   10  \n",
      "18790454    15   10  \n",
      "18790455    15   10  \n",
      "18790456    15   10  \n",
      "18790457    15   10  \n",
      "18790458    15   10  \n",
      "18790459    15   10  \n",
      "18790460    15   10  \n",
      "18790461    15   10  \n",
      "18790462    15   10  \n",
      "18790463    15   10  \n",
      "18790464    15   10  \n",
      "18790465    15   10  \n",
      "18790466    15   10  \n",
      "18790467    15   10  \n",
      "18790468    15   10  \n",
      "\n",
      "[166653589 rows x 9 columns]\n",
      "train_ip_contains_training_day unique ips: 93936\n",
      "train_ip_contains_training_day unique ips: 38155\n",
      "split attributed data:\n",
      "len: 181313\n",
      "training data len: 18790469\n",
      "a given IP address within each hour...\n",
      "count ip with group by: ['ip', 'day', 'hour']\n",
      "added features: ['ip_day_hourcount']\n",
      "count ip with group by: ['ip', 'app']\n",
      "count ip with group by in hist data: ['ip', 'app']\n",
      "count ip attribution with group by in hist data: ['ip', 'app']\n",
      "added features: ['ip_appcount', 'ip_appcount_in_hist', 'ip_appcount_attribution_in_hist', 'ip_appcount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'channel']\n",
      "count ip with group by in hist data: ['ip', 'channel']\n",
      "count ip attribution with group by in hist data: ['ip', 'channel']\n",
      "added features: ['ip_channelcount', 'ip_channelcount_in_hist', 'ip_channelcount_attribution_in_hist', 'ip_channelcount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'channel', 'app']\n",
      "count ip with group by in hist data: ['ip', 'channel', 'app']\n",
      "count ip attribution with group by in hist data: ['ip', 'channel', 'app']\n",
      "added features: ['ip_channel_appcount', 'ip_channel_appcount_in_hist', 'ip_channel_appcount_attribution_in_hist', 'ip_channel_appcount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'app', 'os']\n",
      "count ip with group by in hist data: ['ip', 'app', 'os']\n",
      "count ip attribution with group by in hist data: ['ip', 'app', 'os']\n",
      "added features: ['ip_app_oscount', 'ip_app_oscount_in_hist', 'ip_app_oscount_attribution_in_hist', 'ip_app_oscount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip']\n",
      "count ip with group by in hist data: ['ip']\n",
      "count ip attribution with group by in hist data: ['ip']\n",
      "added features: ['ipcount', 'ipcount_in_hist', 'ipcount_attribution_in_hist', 'ipcount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'hour', 'channel']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count ip with group by in hist data: ['ip', 'hour', 'channel']\n",
      "count ip attribution with group by in hist data: ['ip', 'hour', 'channel']\n",
      "added features: ['ip_hour_channelcount', 'ip_hour_channelcount_in_hist', 'ip_hour_channelcount_attribution_in_hist', 'ip_hour_channelcount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'hour', 'os']\n",
      "count ip with group by in hist data: ['ip', 'hour', 'os']\n",
      "count ip attribution with group by in hist data: ['ip', 'hour', 'os']\n",
      "added features: ['ip_hour_oscount', 'ip_hour_oscount_in_hist', 'ip_hour_oscount_attribution_in_hist', 'ip_hour_oscount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'hour', 'app']\n",
      "count ip with group by in hist data: ['ip', 'hour', 'app']\n",
      "count ip attribution with group by in hist data: ['ip', 'hour', 'app']\n",
      "added features: ['ip_hour_appcount', 'ip_hour_appcount_in_hist', 'ip_hour_appcount_attribution_in_hist', 'ip_hour_appcount_attribution_rate_in_hist']\n",
      "count ip with group by: ['ip', 'hour', 'device']\n",
      "count ip with group by in hist data: ['ip', 'hour', 'device']\n",
      "count ip attribution with group by in hist data: ['ip', 'hour', 'device']\n",
      "added features: ['ip_hour_devicecount', 'ip_hour_devicecount_in_hist', 'ip_hour_devicecount_attribution_in_hist', 'ip_hour_devicecount_attribution_rate_in_hist']\n"
     ]
    }
   ],
   "source": [
    "test, new_test_features = gen_test_df(True)\n",
    "\n",
    "\n",
    "#gen_ffm_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1.726332e+07\n",
      "mean     5.169197e+04\n",
      "std      1.808978e+05\n",
      "min      1.000000e+00\n",
      "25%      2.532000e+03\n",
      "50%      6.535000e+03\n",
      "75%      1.616900e+04\n",
      "max      1.206303e+06\n",
      "Name: ipcount_in_hist, dtype: float64\n",
      "          app  channel          click_time  device      ip  is_attributed  os  \\\n",
      "0           9      107 2017-11-10 04:00:00       1    5744              0   3   \n",
      "1           9      466 2017-11-10 04:00:00       1  119901              0   3   \n",
      "2          21      128 2017-11-10 04:00:00       1   72287              0  19   \n",
      "3          15      111 2017-11-10 04:00:00       1   78477              0  13   \n",
      "4          12      328 2017-11-10 04:00:00       1  123080              0  13   \n",
      "5          18      107 2017-11-10 04:00:00       1  110769              0  13   \n",
      "6           3      137 2017-11-10 04:00:00       1   12540              0   1   \n",
      "7          27      153 2017-11-10 04:00:00       1   88637              0  19   \n",
      "8          18      107 2017-11-10 04:00:00       1   14932              0  10   \n",
      "9          12      424 2017-11-10 04:00:00       1  123701              0  53   \n",
      "10         26      477 2017-11-10 04:00:00       1  106056              0  19   \n",
      "11          3      137 2017-11-10 04:00:00       1  111025              0  19   \n",
      "12         12      265 2017-11-10 04:00:00       1   16050              0  13   \n",
      "13          9      244 2017-11-10 04:00:00       1   31555              0  13   \n",
      "14         12      242 2017-11-10 04:00:00       1    3009              0  25   \n",
      "15         14      480 2017-11-10 04:00:00       1   17149              0  49   \n",
      "16         18      107 2017-11-10 04:00:00       1  104009              0  17   \n",
      "17         14      480 2017-11-10 04:00:00       1   17149              0  49   \n",
      "18         27      122 2017-11-10 04:00:00       1   80209              0  13   \n",
      "19          3      417 2017-11-10 04:00:00       1   41399              0   8   \n",
      "20         12      178 2017-11-10 04:00:00       1   43655              0  15   \n",
      "21          8      145 2017-11-10 04:00:00       1   37338              0   8   \n",
      "22         13      477 2017-11-10 04:00:00       1   72562              0  19   \n",
      "23         12      242 2017-11-10 04:00:00       1   61583              0  13   \n",
      "24         18      107 2017-11-10 04:00:00       1   48240              0  42   \n",
      "25         27      153 2017-11-10 04:00:00       1   46401              0  22   \n",
      "26          2      258 2017-11-10 04:00:00       1   95155              0  16   \n",
      "27          9      445 2017-11-10 04:00:00       1  114220              0  13   \n",
      "28         18      134 2017-11-10 04:00:00       1   76736              0  39   \n",
      "29         12      178 2017-11-10 04:00:00       1   35834              0  13   \n",
      "...       ...      ...                 ...     ...     ...            ...  ..   \n",
      "18790439   27      153 2017-11-10 15:00:00       1   51432              0  13   \n",
      "18790440   14      401 2017-11-10 15:00:00       1   14334              0  19   \n",
      "18790441    9      334 2017-11-10 15:00:00       1   16749              0  13   \n",
      "18790442   23      153 2017-11-10 15:00:00       1   17814              0  13   \n",
      "18790443   21      232 2017-11-10 15:00:00       1    8825              0  13   \n",
      "18790444    8      259 2017-11-10 15:00:00       2  115536              0  13   \n",
      "18790445    2      205 2017-11-10 15:00:00       1  121472              0  19   \n",
      "18790446   12      242 2017-11-10 15:00:00       1   38000              0  12   \n",
      "18790447    1      125 2017-11-10 15:00:00       1   66176              0  19   \n",
      "18790448    2      205 2017-11-10 15:00:00       1   25553              0  22   \n",
      "18790449   21      128 2017-11-10 15:00:00       2  119531              0  19   \n",
      "18790450   13      469 2017-11-10 15:00:00       1   14062              0  53   \n",
      "18790451   14      442 2017-11-10 15:00:00       1   48536              0  19   \n",
      "18790452    1      125 2017-11-10 15:00:00       1   93291              0  19   \n",
      "18790453    9      258 2017-11-10 15:00:00       1   93291              0  19   \n",
      "18790454    1      125 2017-11-10 15:00:00       1   55874              0  22   \n",
      "18790455    9      145 2017-11-10 15:00:00       1   93291              0  19   \n",
      "18790456    8      259 2017-11-10 15:00:00       1  100697              0  18   \n",
      "18790457   20      259 2017-11-10 15:00:00       1   93291              0  19   \n",
      "18790458    2      452 2017-11-10 15:00:00       1   85329              0  14   \n",
      "18790459   15      140 2017-11-10 15:00:00       1  102467              0  17   \n",
      "18790460    9      445 2017-11-10 15:00:00       1   80537              0  19   \n",
      "18790461    2      237 2017-11-10 15:00:00       2  101214              0  16   \n",
      "18790462   17      128 2017-11-10 15:00:00       1  113418              0  17   \n",
      "18790463   12      135 2017-11-10 15:00:00       1   69245              0  13   \n",
      "18790464    9      127 2017-11-10 15:00:00       1   99442              0  13   \n",
      "18790465   23      153 2017-11-10 15:00:00       1   88046              0  37   \n",
      "18790466   18      265 2017-11-10 15:00:00       1   81398              0  17   \n",
      "18790467   27      122 2017-11-10 15:00:00       1  123236              0  13   \n",
      "18790468   12      265 2017-11-10 15:00:00       2   73516              0  27   \n",
      "\n",
      "          hour  day  ip_day_hourcount  \\\n",
      "0            4   10                34   \n",
      "1            4   10               403   \n",
      "2            4   10               229   \n",
      "3            4   10               239   \n",
      "4            4   10                60   \n",
      "5            4   10               120   \n",
      "6            4   10                90   \n",
      "7            4   10                93   \n",
      "8            4   10               106   \n",
      "9            4   10               539   \n",
      "10           4   10                43   \n",
      "11           4   10              3848   \n",
      "12           4   10               102   \n",
      "13           4   10                78   \n",
      "14           4   10               224   \n",
      "15           4   10              4725   \n",
      "16           4   10                 5   \n",
      "17           4   10              4725   \n",
      "18           4   10               169   \n",
      "19           4   10               367   \n",
      "20           4   10                18   \n",
      "21           4   10                57   \n",
      "22           4   10                40   \n",
      "23           4   10                75   \n",
      "24           4   10              2442   \n",
      "25           4   10                86   \n",
      "26           4   10               109   \n",
      "27           4   10              2286   \n",
      "28           4   10               151   \n",
      "29           4   10               128   \n",
      "...        ...  ...               ...   \n",
      "18790439    15   10                 1   \n",
      "18790440    15   10                 1   \n",
      "18790441    15   10                 1   \n",
      "18790442    15   10                 1   \n",
      "18790443    15   10                 3   \n",
      "18790444    15   10                 1   \n",
      "18790445    15   10                 2   \n",
      "18790446    15   10                 1   \n",
      "18790447    15   10                 6   \n",
      "18790448    15   10                 1   \n",
      "18790449    15   10                 1   \n",
      "18790450    15   10                 1   \n",
      "18790451    15   10                 2   \n",
      "18790452    15   10                 7   \n",
      "18790453    15   10                 7   \n",
      "18790454    15   10                 6   \n",
      "18790455    15   10                 7   \n",
      "18790456    15   10                 1   \n",
      "18790457    15   10                 7   \n",
      "18790458    15   10                 2   \n",
      "18790459    15   10                 6   \n",
      "18790460    15   10                 6   \n",
      "18790461    15   10                 1   \n",
      "18790462    15   10                 2   \n",
      "18790463    15   10                 1   \n",
      "18790464    15   10                 2   \n",
      "18790465    15   10                 1   \n",
      "18790466    15   10                 2   \n",
      "18790467    15   10                 1   \n",
      "18790468    15   10                 4   \n",
      "\n",
      "                              ...                       \\\n",
      "0                             ...                        \n",
      "1                             ...                        \n",
      "2                             ...                        \n",
      "3                             ...                        \n",
      "4                             ...                        \n",
      "5                             ...                        \n",
      "6                             ...                        \n",
      "7                             ...                        \n",
      "8                             ...                        \n",
      "9                             ...                        \n",
      "10                            ...                        \n",
      "11                            ...                        \n",
      "12                            ...                        \n",
      "13                            ...                        \n",
      "14                            ...                        \n",
      "15                            ...                        \n",
      "16                            ...                        \n",
      "17                            ...                        \n",
      "18                            ...                        \n",
      "19                            ...                        \n",
      "20                            ...                        \n",
      "21                            ...                        \n",
      "22                            ...                        \n",
      "23                            ...                        \n",
      "24                            ...                        \n",
      "25                            ...                        \n",
      "26                            ...                        \n",
      "27                            ...                        \n",
      "28                            ...                        \n",
      "29                            ...                        \n",
      "...                           ...                        \n",
      "18790439                      ...                        \n",
      "18790440                      ...                        \n",
      "18790441                      ...                        \n",
      "18790442                      ...                        \n",
      "18790443                      ...                        \n",
      "18790444                      ...                        \n",
      "18790445                      ...                        \n",
      "18790446                      ...                        \n",
      "18790447                      ...                        \n",
      "18790448                      ...                        \n",
      "18790449                      ...                        \n",
      "18790450                      ...                        \n",
      "18790451                      ...                        \n",
      "18790452                      ...                        \n",
      "18790453                      ...                        \n",
      "18790454                      ...                        \n",
      "18790455                      ...                        \n",
      "18790456                      ...                        \n",
      "18790457                      ...                        \n",
      "18790458                      ...                        \n",
      "18790459                      ...                        \n",
      "18790460                      ...                        \n",
      "18790461                      ...                        \n",
      "18790462                      ...                        \n",
      "18790463                      ...                        \n",
      "18790464                      ...                        \n",
      "18790465                      ...                        \n",
      "18790466                      ...                        \n",
      "18790467                      ...                        \n",
      "18790468                      ...                        \n",
      "\n",
      "          ip_hour_oscount_attribution_in_hist  \\\n",
      "0                                         NaN   \n",
      "1                                         NaN   \n",
      "2                                         NaN   \n",
      "3                                         1.0   \n",
      "4                                         NaN   \n",
      "5                                         NaN   \n",
      "6                                         NaN   \n",
      "7                                         1.0   \n",
      "8                                         NaN   \n",
      "9                                         NaN   \n",
      "10                                        NaN   \n",
      "11                                        NaN   \n",
      "12                                        NaN   \n",
      "13                                        NaN   \n",
      "14                                        NaN   \n",
      "15                                        NaN   \n",
      "16                                        NaN   \n",
      "17                                        NaN   \n",
      "18                                        NaN   \n",
      "19                                        NaN   \n",
      "20                                        NaN   \n",
      "21                                        NaN   \n",
      "22                                        NaN   \n",
      "23                                        NaN   \n",
      "24                                        NaN   \n",
      "25                                        NaN   \n",
      "26                                        NaN   \n",
      "27                                        NaN   \n",
      "28                                        NaN   \n",
      "29                                        NaN   \n",
      "...                                       ...   \n",
      "18790439                                  NaN   \n",
      "18790440                                  NaN   \n",
      "18790441                                  NaN   \n",
      "18790442                                  NaN   \n",
      "18790443                                  NaN   \n",
      "18790444                                  NaN   \n",
      "18790445                                  NaN   \n",
      "18790446                                  NaN   \n",
      "18790447                                  NaN   \n",
      "18790448                                  NaN   \n",
      "18790449                                  2.0   \n",
      "18790450                                  NaN   \n",
      "18790451                                  NaN   \n",
      "18790452                                  NaN   \n",
      "18790453                                  NaN   \n",
      "18790454                                  NaN   \n",
      "18790455                                  NaN   \n",
      "18790456                                  NaN   \n",
      "18790457                                  NaN   \n",
      "18790458                                  NaN   \n",
      "18790459                                  NaN   \n",
      "18790460                                  NaN   \n",
      "18790461                                  NaN   \n",
      "18790462                                  NaN   \n",
      "18790463                                  NaN   \n",
      "18790464                                  NaN   \n",
      "18790465                                  NaN   \n",
      "18790466                                  NaN   \n",
      "18790467                                  NaN   \n",
      "18790468                                  NaN   \n",
      "\n",
      "          ip_hour_oscount_attribution_rate_in_hist  ip_hour_appcount  \\\n",
      "0                                              NaN                 8   \n",
      "1                                              NaN                50   \n",
      "2                                              NaN                13   \n",
      "3                                         6.896552                10   \n",
      "4                                              NaN                 7   \n",
      "5                                              NaN                16   \n",
      "6                                              NaN                16   \n",
      "7                                        18.867925                 1   \n",
      "8                                              NaN                13   \n",
      "9                                              NaN                52   \n",
      "10                                             NaN                 1   \n",
      "11                                             NaN               586   \n",
      "12                                             NaN                14   \n",
      "13                                             NaN                 6   \n",
      "14                                             NaN                20   \n",
      "15                                             NaN               197   \n",
      "16                                             NaN                 1   \n",
      "17                                             NaN               197   \n",
      "18                                             NaN                 1   \n",
      "19                                             NaN                35   \n",
      "20                                             NaN                 5   \n",
      "21                                             NaN                 2   \n",
      "22                                             NaN                 2   \n",
      "23                                             NaN                 8   \n",
      "24                                             NaN               194   \n",
      "25                                             NaN                 2   \n",
      "26                                             NaN                11   \n",
      "27                                             NaN               350   \n",
      "28                                             NaN                14   \n",
      "29                                             NaN                11   \n",
      "...                                            ...               ...   \n",
      "18790439                                       NaN                 1   \n",
      "18790440                                       NaN                 1   \n",
      "18790441                                       NaN                 1   \n",
      "18790442                                       NaN                 1   \n",
      "18790443                                       NaN                 1   \n",
      "18790444                                       NaN                 1   \n",
      "18790445                                       NaN                 1   \n",
      "18790446                                       NaN                 1   \n",
      "18790447                                       NaN                 1   \n",
      "18790448                                       NaN                 1   \n",
      "18790449                                  1.255493                 1   \n",
      "18790450                                       NaN                 1   \n",
      "18790451                                       NaN                 1   \n",
      "18790452                                       NaN                 1   \n",
      "18790453                                       NaN                 3   \n",
      "18790454                                       NaN                 1   \n",
      "18790455                                       NaN                 3   \n",
      "18790456                                       NaN                 1   \n",
      "18790457                                       NaN                 1   \n",
      "18790458                                       NaN                 1   \n",
      "18790459                                       NaN                 1   \n",
      "18790460                                       NaN                 2   \n",
      "18790461                                       NaN                 1   \n",
      "18790462                                       NaN                 1   \n",
      "18790463                                       NaN                 1   \n",
      "18790464                                       NaN                 1   \n",
      "18790465                                       NaN                 1   \n",
      "18790466                                       NaN                 2   \n",
      "18790467                                       NaN                 1   \n",
      "18790468                                       NaN                 1   \n",
      "\n",
      "          ip_hour_appcount_in_hist  ip_hour_appcount_attribution_in_hist  \\\n",
      "0                              3.0                                   NaN   \n",
      "1                            117.0                                   NaN   \n",
      "2                             36.0                                   NaN   \n",
      "3                             44.0                                   NaN   \n",
      "4                              5.0                                   NaN   \n",
      "5                             17.0                                   NaN   \n",
      "6                             64.0                                   NaN   \n",
      "7                              4.0                                   NaN   \n",
      "8                             31.0                                   NaN   \n",
      "9                            137.0                                   NaN   \n",
      "10                             3.0                                   NaN   \n",
      "11                          2176.0                                   NaN   \n",
      "12                            17.0                                   NaN   \n",
      "13                            10.0                                   NaN   \n",
      "14                            81.0                                   NaN   \n",
      "15                           581.0                                   NaN   \n",
      "16                             NaN                                   NaN   \n",
      "17                           581.0                                   NaN   \n",
      "18                             1.0                                   NaN   \n",
      "19                           299.0                                   NaN   \n",
      "20                            31.0                                   NaN   \n",
      "21                             1.0                                   NaN   \n",
      "22                             1.0                                   NaN   \n",
      "23                            11.0                                   NaN   \n",
      "24                           381.0                                   NaN   \n",
      "25                             3.0                                   NaN   \n",
      "26                            33.0                                   NaN   \n",
      "27                           606.0                                   NaN   \n",
      "28                            24.0                                   NaN   \n",
      "29                            54.0                                   NaN   \n",
      "...                            ...                                   ...   \n",
      "18790439                       NaN                                   NaN   \n",
      "18790440                       4.0                                   NaN   \n",
      "18790441                      10.0                                   NaN   \n",
      "18790442                      16.0                                   NaN   \n",
      "18790443                       3.0                                   NaN   \n",
      "18790444                       1.0                                   NaN   \n",
      "18790445                     590.0                                   NaN   \n",
      "18790446                       5.0                                   NaN   \n",
      "18790447                      42.0                                   NaN   \n",
      "18790448                    1860.0                                   NaN   \n",
      "18790449                     181.0                                   NaN   \n",
      "18790450                       2.0                                   NaN   \n",
      "18790451                       NaN                                   NaN   \n",
      "18790452                      16.0                                   NaN   \n",
      "18790453                     115.0                                   NaN   \n",
      "18790454                      64.0                                   NaN   \n",
      "18790455                     115.0                                   NaN   \n",
      "18790456                       2.0                                   NaN   \n",
      "18790457                      10.0                                   NaN   \n",
      "18790458                    1086.0                                   NaN   \n",
      "18790459                     244.0                                   NaN   \n",
      "18790460                       2.0                                   NaN   \n",
      "18790461                     268.0                                   NaN   \n",
      "18790462                       8.0                                   NaN   \n",
      "18790463                      34.0                                   NaN   \n",
      "18790464                       NaN                                   NaN   \n",
      "18790465                      13.0                                   NaN   \n",
      "18790466                      24.0                                   NaN   \n",
      "18790467                       1.0                                   NaN   \n",
      "18790468                   17439.0                                   5.0   \n",
      "\n",
      "          ip_hour_appcount_attribution_rate_in_hist  ip_hour_devicecount  \\\n",
      "0                                               NaN                   34   \n",
      "1                                               NaN                  400   \n",
      "2                                               NaN                  229   \n",
      "3                                               NaN                  239   \n",
      "4                                               NaN                   59   \n",
      "5                                               NaN                  120   \n",
      "6                                               NaN                   87   \n",
      "7                                               NaN                   92   \n",
      "8                                               NaN                  105   \n",
      "9                                               NaN                  441   \n",
      "10                                              NaN                   40   \n",
      "11                                              NaN                 3349   \n",
      "12                                              NaN                  102   \n",
      "13                                              NaN                   77   \n",
      "14                                              NaN                  222   \n",
      "15                                              NaN                 3753   \n",
      "16                                              NaN                    5   \n",
      "17                                              NaN                 3753   \n",
      "18                                              NaN                  169   \n",
      "19                                              NaN                  297   \n",
      "20                                              NaN                   17   \n",
      "21                                              NaN                   45   \n",
      "22                                              NaN                   40   \n",
      "23                                              NaN                   75   \n",
      "24                                              NaN                 2269   \n",
      "25                                              NaN                   86   \n",
      "26                                              NaN                  109   \n",
      "27                                              NaN                 1969   \n",
      "28                                              NaN                  147   \n",
      "29                                              NaN                  128   \n",
      "...                                             ...                  ...   \n",
      "18790439                                        NaN                    1   \n",
      "18790440                                        NaN                    1   \n",
      "18790441                                        NaN                    1   \n",
      "18790442                                        NaN                    1   \n",
      "18790443                                        NaN                    3   \n",
      "18790444                                        NaN                    1   \n",
      "18790445                                        NaN                    2   \n",
      "18790446                                        NaN                    1   \n",
      "18790447                                        NaN                    6   \n",
      "18790448                                        NaN                    1   \n",
      "18790449                                        NaN                    1   \n",
      "18790450                                        NaN                    1   \n",
      "18790451                                        NaN                    2   \n",
      "18790452                                        NaN                    7   \n",
      "18790453                                        NaN                    7   \n",
      "18790454                                        NaN                    6   \n",
      "18790455                                        NaN                    7   \n",
      "18790456                                        NaN                    1   \n",
      "18790457                                        NaN                    7   \n",
      "18790458                                        NaN                    2   \n",
      "18790459                                        NaN                    6   \n",
      "18790460                                        NaN                    6   \n",
      "18790461                                        NaN                    1   \n",
      "18790462                                        NaN                    2   \n",
      "18790463                                        NaN                    1   \n",
      "18790464                                        NaN                    2   \n",
      "18790465                                        NaN                    1   \n",
      "18790466                                        NaN                    2   \n",
      "18790467                                        NaN                    1   \n",
      "18790468                                   0.286714                    1   \n",
      "\n",
      "          ip_hour_devicecount_in_hist  \\\n",
      "0                                63.0   \n",
      "1                              1236.0   \n",
      "2                              1064.0   \n",
      "3                               740.0   \n",
      "4                                85.0   \n",
      "5                               273.0   \n",
      "6                               268.0   \n",
      "7                               368.0   \n",
      "8                               413.0   \n",
      "9                              1216.0   \n",
      "10                              101.0   \n",
      "11                             9570.0   \n",
      "12                              235.0   \n",
      "13                              221.0   \n",
      "14                              776.0   \n",
      "15                            12516.0   \n",
      "16                               17.0   \n",
      "17                            12516.0   \n",
      "18                              102.0   \n",
      "19                             1292.0   \n",
      "20                              191.0   \n",
      "21                              150.0   \n",
      "22                              153.0   \n",
      "23                              133.0   \n",
      "24                             5425.0   \n",
      "25                              245.0   \n",
      "26                              280.0   \n",
      "27                             6465.0   \n",
      "28                              303.0   \n",
      "29                              435.0   \n",
      "...                               ...   \n",
      "18790439                          NaN   \n",
      "18790440                         56.0   \n",
      "18790441                         62.0   \n",
      "18790442                        602.0   \n",
      "18790443                        110.0   \n",
      "18790444                          9.0   \n",
      "18790445                       3992.0   \n",
      "18790446                         43.0   \n",
      "18790447                       1275.0   \n",
      "18790448                       2675.0   \n",
      "18790449                        984.0   \n",
      "18790450                        152.0   \n",
      "18790451                         12.0   \n",
      "18790452                       1287.0   \n",
      "18790453                       1287.0   \n",
      "18790454                        950.0   \n",
      "18790455                       1287.0   \n",
      "18790456                        134.0   \n",
      "18790457                       1287.0   \n",
      "18790458                       3545.0   \n",
      "18790459                       2006.0   \n",
      "18790460                         51.0   \n",
      "18790461                        100.0   \n",
      "18790462                        397.0   \n",
      "18790463                        154.0   \n",
      "18790464                          3.0   \n",
      "18790465                        517.0   \n",
      "18790466                        360.0   \n",
      "18790467                         22.0   \n",
      "18790468                       9183.0   \n",
      "\n",
      "          ip_hour_devicecount_attribution_in_hist  \\\n",
      "0                                             NaN   \n",
      "1                                             NaN   \n",
      "2                                             NaN   \n",
      "3                                             1.0   \n",
      "4                                             NaN   \n",
      "5                                             NaN   \n",
      "6                                             NaN   \n",
      "7                                             1.0   \n",
      "8                                             NaN   \n",
      "9                                             NaN   \n",
      "10                                            NaN   \n",
      "11                                            1.0   \n",
      "12                                            NaN   \n",
      "13                                            NaN   \n",
      "14                                            1.0   \n",
      "15                                            3.0   \n",
      "16                                            NaN   \n",
      "17                                            3.0   \n",
      "18                                            NaN   \n",
      "19                                            2.0   \n",
      "20                                            NaN   \n",
      "21                                            NaN   \n",
      "22                                            NaN   \n",
      "23                                            NaN   \n",
      "24                                            1.0   \n",
      "25                                            1.0   \n",
      "26                                            NaN   \n",
      "27                                            NaN   \n",
      "28                                            NaN   \n",
      "29                                            NaN   \n",
      "...                                           ...   \n",
      "18790439                                      NaN   \n",
      "18790440                                      NaN   \n",
      "18790441                                      NaN   \n",
      "18790442                                      NaN   \n",
      "18790443                                      NaN   \n",
      "18790444                                      NaN   \n",
      "18790445                                      NaN   \n",
      "18790446                                      NaN   \n",
      "18790447                                      NaN   \n",
      "18790448                                      2.0   \n",
      "18790449                                      NaN   \n",
      "18790450                                      NaN   \n",
      "18790451                                      NaN   \n",
      "18790452                                      1.0   \n",
      "18790453                                      1.0   \n",
      "18790454                                      NaN   \n",
      "18790455                                      1.0   \n",
      "18790456                                      NaN   \n",
      "18790457                                      1.0   \n",
      "18790458                                      1.0   \n",
      "18790459                                      NaN   \n",
      "18790460                                      NaN   \n",
      "18790461                                      NaN   \n",
      "18790462                                      NaN   \n",
      "18790463                                      NaN   \n",
      "18790464                                      NaN   \n",
      "18790465                                      NaN   \n",
      "18790466                                      NaN   \n",
      "18790467                                      NaN   \n",
      "18790468                                      NaN   \n",
      "\n",
      "          ip_hour_devicecount_attribution_rate_in_hist  \n",
      "0                                                  NaN  \n",
      "1                                                  NaN  \n",
      "2                                                  NaN  \n",
      "3                                             1.351351  \n",
      "4                                                  NaN  \n",
      "5                                                  NaN  \n",
      "6                                                  NaN  \n",
      "7                                             2.717391  \n",
      "8                                                  NaN  \n",
      "9                                                  NaN  \n",
      "10                                                 NaN  \n",
      "11                                            0.104493  \n",
      "12                                                 NaN  \n",
      "13                                                 NaN  \n",
      "14                                            1.288660  \n",
      "15                                            0.239693  \n",
      "16                                                 NaN  \n",
      "17                                            0.239693  \n",
      "18                                                 NaN  \n",
      "19                                            1.547988  \n",
      "20                                                 NaN  \n",
      "21                                                 NaN  \n",
      "22                                                 NaN  \n",
      "23                                                 NaN  \n",
      "24                                            0.184332  \n",
      "25                                            4.081633  \n",
      "26                                                 NaN  \n",
      "27                                                 NaN  \n",
      "28                                                 NaN  \n",
      "29                                                 NaN  \n",
      "...                                                ...  \n",
      "18790439                                           NaN  \n",
      "18790440                                           NaN  \n",
      "18790441                                           NaN  \n",
      "18790442                                           NaN  \n",
      "18790443                                           NaN  \n",
      "18790444                                           NaN  \n",
      "18790445                                           NaN  \n",
      "18790446                                           NaN  \n",
      "18790447                                           NaN  \n",
      "18790448                                      0.747664  \n",
      "18790449                                           NaN  \n",
      "18790450                                           NaN  \n",
      "18790451                                           NaN  \n",
      "18790452                                      0.777001  \n",
      "18790453                                      0.777001  \n",
      "18790454                                           NaN  \n",
      "18790455                                      0.777001  \n",
      "18790456                                           NaN  \n",
      "18790457                                      0.777001  \n",
      "18790458                                      0.282087  \n",
      "18790459                                           NaN  \n",
      "18790460                                           NaN  \n",
      "18790461                                           NaN  \n",
      "18790462                                           NaN  \n",
      "18790463                                           NaN  \n",
      "18790464                                           NaN  \n",
      "18790465                                           NaN  \n",
      "18790466                                           NaN  \n",
      "18790467                                           NaN  \n",
      "18790468                                           NaN  \n",
      "\n",
      "[18790469 rows x 46 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing the submission data into a csv file...\n",
      "All done...\n"
     ]
    }
   ],
   "source": [
    "print(test['ipcount_in_hist'].describe())\n",
    "\n",
    "print(test)\n",
    "\n",
    "\n",
    "lgb_saved_model = lgb.Booster(model_file='model.txt.01-04-2018_10:59:15')\n",
    "\n",
    "submit = pd.read_csv(path_test, dtype='int', usecols=['click_id'])\n",
    "\n",
    "predictors1 = categorical + new_test_features\n",
    "submit['is_attributed'] = lgb_saved_model.predict(test[predictors1], num_iteration=lgb_saved_model.best_iteration)\n",
    "\n",
    "print(\"Writing the submission data into a csv file...\")\n",
    "\n",
    "submit.to_csv(get_dated_filename(\"submission_notebook.csv\"),index=False)\n",
    "\n",
    "print(\"All done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ipcount_in_hist isna\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(test.query('ipcount_in_hist isna')['ipcount_in_hist'].describe())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
